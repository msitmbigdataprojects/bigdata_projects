{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">MIS 285N: Big Data and Distributed Programming</p>\n",
    "# <p style=\"text-align: center;\">Project - 1 : Apache Spark</p>\n",
    "## <p style=\"text-align: center;\">Instructor: Dr. Ramesh Yerraballi</p>\n",
    "## <p style=\"text-align: center;\">Due: Tuesday, September 14th submitted via Canvas by 11:59 pm</p>\n",
    "\n",
    "Your work should be written in a **Jupyter notebook**.   \n",
    "\n",
    "Also, please make sure your code runs in your notebook before submitting.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "This project is based on Map-Reduce Framework. In these you will get to work with Spark and will get to know how \n",
    "does spark work, what functionalities does spark provide, what does map-reduce framework do and why is it useful. \n",
    "\n",
    "In this project you will be implementing a basic song recommender system. You will be given a dataset where there are multiple csv files. These csv files have data corresponding to song play count and song information.\n",
    "\n",
    "The data you would be using will be provided in a zip file along with this notebook. The __msd.zip__ archive contains:\n",
    "1. **'kaggle_visible_evaluation_triplets.txt'**. We will be using the visible part of the testing data to understand the working on Apache Spark.  The user's listening history is provided as: (user, song, play count).  \n",
    "2. In **'kaggle_songs.txt'** file, each song is marked using an index for easier representation of songs.  \n",
    "3. And **'kaggle_users.txt'** file is the canonical list of user identifiers.\n",
    "4. Take **'MSDChallengeGettingstarted.pdf'** as your reference.\n",
    "\n",
    "\n",
    "\n",
    "### **What to turn in?**  \n",
    "\n",
    "A zip folder which will have:\n",
    "1. Jupyter Notebook\n",
    "2. A brief report in PDF format on what features you used for recommendation. And a brief explanation of flow of your code. For example,  what RDD does what or, why it was created.\n",
    "3. datasets folder with the csv files you are using in your notebook.\n",
    "4. Notebook should use relative path to the csv files in datasets folder.\n",
    "5. Name of the zip folder - `<your_name>_<your_partner_name>.zip`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project consists of 4 questions:  \n",
    "\n",
    "1. Create an RDD with _kaggle_visible_evaluation_triplets.txt_ and replace the song name with the song index from _kaggle_songs.txt_. Identify the number of songs that do not have any rating. \n",
    "2. Generate song ratings based on the song play count as a normalized score between 0 and 1. \n",
    "3. Identify the popular song based on this rating and recommend songs to user, given user id based on the algorithm used in Movie recommender system from class. \n",
    "4. Using Cosine similarity function, identify pair-wise similarity between each pair of users and generate the top 5 most similar users without an overlap in users. \n",
    "\n",
    "The above list is the higer level idea about the questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Starter code ####\n",
    "import findspark\n",
    "findspark.init('/opt/homebrew/Cellar/apache-spark/3.1.2/libexec')\n",
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"Songs\")\n",
    "sc = SparkContext(conf = conf)\n",
    "#### These lines are to tell jupyter where to find Apache Spark ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read triplet file into RDD\n",
    "triplet_rdd = sc.textFile(r\"kaggle_visible_evaluation_triplets.txt\") \\\n",
    "    .map(lambda line: line.split(\"\\t\")) \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: \n",
    "Replace song name with song index and identify the number of songs without user history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Song RDD by getting the data from kaggle_songs.txt. The seperator is a \" \" blank space because that is how data is separated in the text file.\n",
    "song_rdd = sc.textFile(r\"kaggle_songs.txt\") \\\n",
    "    .map(lambda line: line.split(\" \")) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary from the Song RDD\n",
    "song_dict = song_rdd.collectAsMap()\n",
    "\n",
    "\n",
    "# Applying a function to replace all song names in Triplet RDD with the song index using dictionary created above\n",
    "triplet_rdd = triplet_rdd.map(lambda x: (x[0],song_dict[x[1]],int(x[2])\n",
    "                                        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', '25150', 1),\n",
       " ('fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', '68212', 1),\n",
       " ('fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', '87433', 1),\n",
       " ('fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', '123630', 1),\n",
       " ('fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', '58821', 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "triplet_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223007"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a list of all song indexes in the Triplet RDD\n",
    "ratings_list = triplet_rdd.map(lambda x: x[1]).distinct().collect()\n",
    "\n",
    "# Creating a list of all song indexes in the Song RDD\n",
    "songs_list = song_rdd.map(lambda x: x[1]).collect()\n",
    "\n",
    "# Created a \"songs without rating\" list by getting all song indexes that are present in Song RDD but not in Triplet RDD\n",
    "songs_without_rating = list(set(songs_list) - set(ratings_list))\n",
    "len(songs_without_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:\n",
    "Generate song ratings based on the play_count. For example, if (song_1, 5; song_2, 10; song_3, 5) i.e., song_1 is played 5 times, song_2 is played 10 times and song_3 is played 5 times, the normalized rating score should be 0.25, 0.5 and 0.25 respectively. \n",
    "Similarly, generate the rating for all the songs. You may notice that based on all songs, the rating is almost always very low. So, think of the best way to convert song count to ratings. (Hint: Try generating ratings based on each user's song play history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a7db6535e9e7f76152af448875851c2174d36fd1', (10, '24495')), ('a7db6535e9e7f76152af448875851c2174d36fd1', (10, '84076')), ('a7db6535e9e7f76152af448875851c2174d36fd1', (10, '19159')), ('a7db6535e9e7f76152af448875851c2174d36fd1', (10, '347550')), ('a7db6535e9e7f76152af448875851c2174d36fd1', (10, '281233'))]\n",
      "[('a7db6535e9e7f76152af448875851c2174d36fd1', '24495', 0.1), ('a7db6535e9e7f76152af448875851c2174d36fd1', '84076', 0.1), ('a7db6535e9e7f76152af448875851c2174d36fd1', '19159', 0.1), ('a7db6535e9e7f76152af448875851c2174d36fd1', '347550', 0.1), ('a7db6535e9e7f76152af448875851c2174d36fd1', '281233', 0.1)]\n",
      "[('89579', 2.377832862438824), ('374773', 0.9240047229954816), ('234204', 5.476121407418219), ('6743', 1.8158141199421463), ('324001', 0.24995917034133594)]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# reduce triplet_rdd into a tuple of song index and play count - song index is key, play count is value\n",
    "# use reduceby to get song count by adding play count per song index (which is the key)\n",
    "# Note: reduceby uses two different variables but really the variables stand for the same - adding counts in pairs.\n",
    "song_count_rdd = triplet_rdd.map(lambda x: (x[1],x[2])).reduceByKey(lambda x, y: x + y)\n",
    " \n",
    "\n",
    "#get the number of songs played per user  \n",
    "song_user_count_rdd = triplet_rdd.map(lambda x: (x[0],x[2])).reduceByKey(lambda x, y: x + y)\n",
    "user_and_songcount_rdd = song_user_count_rdd.map(lambda x: (x[0],x[1],1)) \n",
    " \n",
    " \n",
    "#get the song list played per user   \n",
    "list_of_user_songs_rdd = triplet_rdd.map(lambda x: (x[0],x[1].split())).reduceByKey(lambda x, y: x + y)\n",
    "user_and_songlist_rdd = list_of_user_songs_rdd.map(lambda x: (x[0],x[1]))\n",
    " \n",
    "user_data_join = user_and_songcount_rdd.join(triplet_rdd)\n",
    "find_avg_per_user = user_data_join.map(lambda x: (x[0],x[1][1],1/x[1][0])) \n",
    "print(find_avg_per_user.take(5))\n",
    "\n",
    "sum_avg_per_song = find_avg_per_user.map(lambda x: (x[1],x[2])).reduceByKey(lambda x, y: x + y)\n",
    "print(sum_avg_per_song.take(5))\n",
    "\n",
    "\n",
    "#find number of users listened to a particular song\n",
    "# multiply sum_avg_per_song with number of users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: \n",
    "For a given user_id (choose one by yourselves), rating, recommend 5 other songs from the list. One way to do this is based on another user who liked the same song liked by this user with rating more than the given rating and recommend the 5 songs based on the matched user's rating. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: \n",
    "1. Compute cosine similarity between all pairs of users. \n",
    "2. Sort the similarity score and print the top-5 similar users. \n",
    "3. If the top-5 user set has an user appearing more than once, ignore that pair and take the next best pair from the sorted list. \n",
    "4. For a given user_id, identify the top-5 similar users and hence song recommendations from other user's list. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
