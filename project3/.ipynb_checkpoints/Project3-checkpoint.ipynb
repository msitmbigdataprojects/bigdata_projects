{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tbfz3zSXBt3H"
   },
   "source": [
    "# <p style=\"text-align: center;\">MIS 284N - Big Data and Distributed Programming</p>\n",
    "## <p style=\"text-align: center;\">Project 3 - Machine Learning using Tensorflow and Google Colab</p>\n",
    "## <p style=\"text-align: center;\">Total points: 100</p>\n",
    "## <p style=\"text-align: center;\">Due: Sunday, October 17th submitted via Canvas by 11:59 pm</p>\n",
    "\n",
    "This will be a in-class project done in teams of 2. \n",
    "\n",
    "In this Project, we will work with CIFAR10 image dataset. \n",
    "The starter code to download the database using keras is given below. \n",
    "Test the project on Google Colab running on a CPU, GPU and TPU\n",
    " \n",
    "\n",
    "# In every line of code, please write a comment to briefly explain what that line is doing.\n",
    "Your grades will be based on your understanding of the code you write! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnHTzAuvxxQT"
   },
   "source": [
    "# Task 1\n",
    "Convert the features in a form that can be given as input to tensorflow library/functions\n",
    "\n",
    "In this task you will perform data augmentation. That is, pre-process the data to make the model more robust. Experiment with data augmentation techniques like rotation, translation, horizontal-, scaling, ZCA whitening and histogram equalization. \n",
    "You can choose any two or more augmentation technique(s) of your choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M6c8xzloyoUD"
   },
   "source": [
    "# Task 2\n",
    "Try to build a Neural Network model, train on the features and report the accuracy.\n",
    "Report your observations on the time taken on CPU and GPU (with and without CuDNN kernel) \n",
    "\n",
    "\n",
    "\n",
    "1.   Create a CNN based model with 4 hidden layers with 64, 128, 256 and 512 units in each succesive layer. Use a 5x5 convolution kernel and change as necessay. \n",
    "2.   Create an LSTM based model with 1 LSTM layer with 256 units. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "LQvjBuuyxblF",
    "outputId": "9e917925-3589-495e-f3e7-08e30c597627"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "Run the LSTM solution in Task2 on a TPU and report the performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
